import pandas, json, os, sklearn
import joblib
from tqdm import tqdm
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sentence_transformers import SentenceTransformer

# === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
with open("train_with_is_bot.json", "r", encoding="utf-8") as f:
    data = json.load(f)

texts = []
labels = []

# –ò–¥—ë–º –ø–æ –≤—Å–µ–º –¥–∏–∞–ª–æ–≥–∞–º –∏ —Å–æ–±–∏—Ä–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
for dialog in data.values():
    for msg in dialog:
        texts.append(msg["text"])
        labels.append(int(msg["is_bot"]))  # 0 - —á–µ–ª–æ–≤–µ–∫, 1 - –±–æ—Ç

print(f"–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(texts)}")

# === –ë—ã—Å—Ç—Ä—ã–µ sentence embeddings ===
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π

embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)

# === –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ ===
X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42)

clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, target_names=["—á–µ–ª–æ–≤–µ–∫", "–±–æ—Ç"]))

joblib.dump(clf, "../api/clf_model.pkl")

def classify_text(text):
    emb = model.encode([text])
    pred = clf.predict(emb)[0]
    return "–±–æ—Ç" if pred == 1 else "—á–µ–ª–æ–≤–µ–∫"

# üîç –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
sample_text = "–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å —Ç–µ–±–µ —Å–µ–≥–æ–¥–Ω—è?"
result = classify_text(sample_text)
print(f"–¢–µ–∫—Å—Ç: {sample_text} ‚Üí {result}")